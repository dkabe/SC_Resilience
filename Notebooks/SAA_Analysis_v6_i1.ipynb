{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "\n",
    "import numpy as np\n",
    "import itertools\n",
    "import random\n",
    "from statistics import stdev\n",
    "import math\n",
    "import ast"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "\n",
    "p_running = 0.9\n",
    "p_failure = 1 - p_running\n",
    "path = '/home/dkabe/Model_brainstorming/SAA_Analysis_v6/Instance_1/'"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "N = [64, 128, 192, 256, 320, 384]\n",
    "#N = [320, 384]\n",
    "batches = 30\n",
    "Products = 3\n",
    "Market = 29\n",
    "text_file = open(path + 'Disruption_scenarios.txt', \"r\")\n",
    "ls = text_file.read().split('\\n')[:-1]\n",
    "Scenarios = list(map(lambda x: ast.literal_eval(x), ls))\n",
    "Probabilities = np.loadtxt(path + \"disruption_probabilities.txt\")\n",
    "num_disruption = len(Scenarios)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "p1_mean = 103500\n",
    "p2_mean = 101500\n",
    "p3_mean = 99750\n",
    "\n",
    "p1_sd = 1650\n",
    "p2_sd = 4125\n",
    "p3_sd = 2000\n",
    "\n",
    "distribution_mat = [[p1_mean, p1_sd],\n",
    "                  [p2_mean, p2_sd],\n",
    "                  [p3_mean, p3_sd]]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "\n",
    "np.random.seed(1)\n",
    "nominal_demand = np.zeros((Products, Market))\n",
    "for m in range(Products):\n",
    "    nominal_demand[m] = np.round(np.random.normal(distribution_mat[0][0], distribution_mat[0][1], size = 29))\n",
    "    nominal_demand[m] = np.round(np.random.normal(distribution_mat[1][0], distribution_mat[1][1], size = 29))\n",
    "    nominal_demand[m] = np.round(np.random.normal(distribution_mat[2][0], distribution_mat[2][1], size = 29))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "delta = np.arange(0.75, 1.255, 0.005)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "delta"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([0.75 , 0.755, 0.76 , 0.765, 0.77 , 0.775, 0.78 , 0.785, 0.79 ,\n",
       "       0.795, 0.8  , 0.805, 0.81 , 0.815, 0.82 , 0.825, 0.83 , 0.835,\n",
       "       0.84 , 0.845, 0.85 , 0.855, 0.86 , 0.865, 0.87 , 0.875, 0.88 ,\n",
       "       0.885, 0.89 , 0.895, 0.9  , 0.905, 0.91 , 0.915, 0.92 , 0.925,\n",
       "       0.93 , 0.935, 0.94 , 0.945, 0.95 , 0.955, 0.96 , 0.965, 0.97 ,\n",
       "       0.975, 0.98 , 0.985, 0.99 , 0.995, 1.   , 1.005, 1.01 , 1.015,\n",
       "       1.02 , 1.025, 1.03 , 1.035, 1.04 , 1.045, 1.05 , 1.055, 1.06 ,\n",
       "       1.065, 1.07 , 1.075, 1.08 , 1.085, 1.09 , 1.095, 1.1  , 1.105,\n",
       "       1.11 , 1.115, 1.12 , 1.125, 1.13 , 1.135, 1.14 , 1.145, 1.15 ,\n",
       "       1.155, 1.16 , 1.165, 1.17 , 1.175, 1.18 , 1.185, 1.19 , 1.195,\n",
       "       1.2  , 1.205, 1.21 , 1.215, 1.22 , 1.225, 1.23 , 1.235, 1.24 ,\n",
       "       1.245, 1.25 ])"
      ]
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "demand_realization = len(delta)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "np.mean(nominal_demand)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "99878.62068965517"
      ]
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "random.seed(1)\n",
    "demand = np.zeros((demand_realization, Products, Market))\n",
    "for r in range(demand_realization):\n",
    "    demand[r] = delta[r]*nominal_demand"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "S = demand_realization*Scenarios\n",
    "S_demand = []\n",
    "S_prob = list(Probabilities)*demand_realization\n",
    "multiplier = sum(S_prob)\n",
    "S_prob = list(map(lambda x: x/multiplier, S_prob))\n",
    "for r in range(demand_realization):\n",
    "    S_demand+=([demand[r]]*num_disruption)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "len(S_demand)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "12928"
      ]
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "source": [
    "random.seed(2)\n",
    "evaluation_indices = random.sample(range(len(S)), 5000)\n",
    "evaluation_set = [S[index] for index in evaluation_indices]\n",
    "evaluation_demand = np.array([S_demand[index] for index in evaluation_indices])\n",
    "eval_probabilities = [S_prob[index] for index in evaluation_indices]\n",
    "p_factor = sum(eval_probabilities)\n",
    "eval_probabilities = list(map(lambda x: x/p_factor, eval_probabilities))\n",
    "#with open(path + 'Evaluation_Set.txt', 'w') as f:\n",
    " #   for item in evaluation_set:\n",
    "  #      f.write(\"%s\\n\" % item)\n",
    "#f.close()\n",
    "#np.savetxt(path + \"p_scen.txt\", eval_probabilities)\n",
    "#np.savetxt(path + \"eval_set_demand.txt\", evaluation_demand.reshape((5000*3,29)))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "source": [
    "N = [64, 128, 192, 256, 320, 384]\n",
    "random.seed(1)\n",
    "for num_scen in N:\n",
    "    for batch in range(batches):\n",
    "        indices = random.sample(range(len(S)), num_scen)\n",
    "        sample_scenarios = [S[index] for index in indices]\n",
    "        p_sample_scenarios = [S_prob[index] for index in indices]\n",
    "        demand = np.array([S_demand[index] for index in indices])\n",
    "        p_factor = 1/np.sum(p_sample_scenarios)\n",
    "        p_sample_scenarios = list(map(lambda x: x*p_factor, p_sample_scenarios))  \n",
    "        #with open(path + 'Scenarios/' + str(num_scen) + '_' + str(batch) + '.txt', 'w+') as f:\n",
    "         #   for item in sample_scenarios:\n",
    "          #      f.write(\"%s\\n\" % item)\n",
    "        #f.close()\n",
    "        #np.savetxt(path + 'Scen_probabilities/' + 'p_scen_' + str(num_scen) + '_' + str(batch) + '.txt', p_sample_scenarios)\n",
    "        #np.savetxt(path + 'Scen_demand/' + 'demand_' + str(num_scen) + '_' + str(batch) + '.txt', demand.reshape((num_scen*Products, Market)))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "source": [
    "N = [320, 384]\n",
    "#random.seed(1)\n",
    "random.seed(3)\n",
    "for num_scen in N:\n",
    "    for batch in range(batches):\n",
    "        indices = random.sample(range(len(S)), num_scen)\n",
    "        sample_scenarios = [S[index] for index in indices]\n",
    "        p_sample_scenarios = [S_prob[index] for index in indices]\n",
    "        demand = np.array([S_demand[index] for index in indices])\n",
    "        p_factor = 1/np.sum(p_sample_scenarios)\n",
    "        p_sample_scenarios = list(map(lambda x: x*p_factor, p_sample_scenarios))  \n",
    "        with open(path + 'Scenarios/' + str(num_scen) + '_' + str(batch) + '.txt', 'w') as f:\n",
    "            for item in sample_scenarios:\n",
    "                f.write(\"%s\\n\" % item)\n",
    "        f.close()\n",
    "        np.savetxt(path + 'Scen_probabilities/' + 'p_scen_' + str(num_scen) + '_' + str(batch) + '.txt', p_sample_scenarios)\n",
    "        np.savetxt(path + 'Scen_demand/' + 'demand_' + str(num_scen) + '_' + str(batch) + '.txt', demand.reshape((num_scen*Products, Market)))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "np.sum(p_sample_scenarios)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "metadata": {},
     "execution_count": 15
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "source": [
    "batches = 30\n",
    "path = '/home/dkabe/Model_brainstorming/SAA_Analysis_v6/Instance_1/'\n",
    "N = [64, 128, 192, 256, 320, 384]\n",
    "p_scen = np.loadtxt('/home/dkabe/Model_brainstorming/SAA_Analysis_v6/Instance_1/p_scen.txt')[:1000]\n",
    "p_factor = 1/np.sum(p_scen)\n",
    "p_scen = list(map(lambda x: x*p_factor, p_scen))\n",
    "for scen in N:\n",
    "    gaps = []\n",
    "    ub_averages = []\n",
    "    ub_max = []\n",
    "    objvals_lb = np.loadtxt(path + \"Objectives/\" + str(scen) + '_results.txt')\n",
    "    avg_lb = (np.mean(objvals_lb))\n",
    "    std_lb = (stdev(objvals_lb))\n",
    "    lbwidth = std_lb/math.sqrt(batches)*2.045\n",
    "    lbmin = round(avg_lb - lbwidth,2)\n",
    "    #print(avg_lb, lbmin)\n",
    "    #print('ci on lower bound = [', round(avg_lb-lbwidth,2), ',', round(avg_lb+lbwidth,2), ']')\n",
    "    for batch in range(batches):\n",
    "        objvals_ub = np.loadtxt(path + \"Upper_Bounds/\" + str(scen) + \"_scenarios/\" + str(scen) + \"_\" + str(batch) + \"_UB_results.txt\")[:1000]\n",
    "        #objvals_ub = np.array([objvals_ub[index] for index in indices])\n",
    "        avg_ub = (np.sum(p_scen*objvals_ub))\n",
    "        std_ub = math.sqrt(np.sum(p_scen*((objvals_ub - avg_ub)**2)))\n",
    "        ubwidth = std_ub/math.sqrt(1000)*1.96\n",
    "        ubmax = round(avg_ub + ubwidth, 2)\n",
    "        gap = round(100*((ubmax - lbmin)/lbmin),2)\n",
    "        ub_averages.append(avg_ub)\n",
    "        gaps.append(gap)\n",
    "        ub_max.append(ubmax)\n",
    "    min_gap = min(filter(lambda x: x >= 0, gaps))\n",
    "    #min_gap = min(gaps)\n",
    "    index = gaps.index(min_gap)\n",
    "    #print(ub_averages[index], ub_max[index], min_gap)\n",
    "    print(avg_lb, \"\\t\", ub_averages[index], \"\\t\", lbmin, \"\\t\", ub_max[index], \"\\t\", min_gap, \"\\t\")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "18262028.950333335 \t 17696487.94159241 \t 17385009.16 \t 18188193.26 \t 4.62 \t\n",
      "17628379.059 \t 17696487.94159241 \t 17041637.33 \t 18188193.26 \t 6.73 \t\n",
      "18347470.76433333 \t 17676877.267909504 \t 17849968.73 \t 18149358.15 \t 1.68 \t\n",
      "18504128.800333332 \t 17676877.267909504 \t 17957841.04 \t 18149358.15 \t 1.07 \t\n",
      "18209225.456333335 \t 17676877.267909504 \t 17852853.74 \t 18149358.15 \t 1.66 \t\n",
      "18587428.45733333 \t 17931927.031775713 \t 18176868.17 \t 18346301.85 \t 0.93 \t\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "source": [
    "# save final number of scenarios to use \n",
    "random.seed(1)\n",
    "indices = random.sample(range(len(S)), 192)\n",
    "sample_scenarios = [S[index] for index in indices]\n",
    "p_sample_scenarios = [S_prob[index] for index in indices]\n",
    "demand = np.array([S_demand[index] for index in indices])\n",
    "p_factor = 1/np.sum(p_sample_scenarios)\n",
    "p_sample_scenarios = list(map(lambda x: x*p_factor, p_sample_scenarios))  \n",
    "#with open(\"/home/dkabe/Model_brainstorming/Input_Data/Realistic/Instance_1/scen_1.txt\", 'w+') as f:\n",
    " #   for item in sample_scenarios:\n",
    "  #      f.write(\"%s\\n\" % item)\n",
    "#f.close()\n",
    "#np.savetxt(\"/home/dkabe/Model_brainstorming/Input_Data/Realistic/Instance_1/p_scen_1.txt\", p_sample_scenarios)\n",
    "#np.savetxt(\"/home/dkabe/Model_brainstorming/Input_Data/Realistic/Instance_1/Demand_1.txt\", demand.reshape((192*Products, Market)))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "source": [
    "l1 = [192, 256, 320, 384]\n",
    "for num in l1:\n",
    "    objvals_lb = np.loadtxt(path + \"Objectives/\" + str(num) + '_results.txt')\n",
    "    print(np.mean(objvals_lb))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "18347470.76433333\n",
      "18504128.800333332\n",
      "18209225.456333335\n",
      "18587428.45733333\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.7.4",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.4 64-bit ('env_gurobi': virtualenv)"
  },
  "interpreter": {
   "hash": "ab66d84091635e28aaa655d19dc257d938f7e6a1e4d5fb0a631906b26faaf625"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}