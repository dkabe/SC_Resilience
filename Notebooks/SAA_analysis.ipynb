{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "import numpy as np\n",
    "import itertools\n",
    "import random\n",
    "from statistics import stdev\n",
    "import math\n",
    "import ast"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "p_running = 0.9\n",
    "p_failure = 1 - p_running\n",
    "path = '/home/dkabe/Model_brainstorming/SAA_Analysis/'"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "provinces = [3, 6]\n",
    "plants = 6\n",
    "dc = 4\n",
    "a5 = list(itertools.product([1, 0], repeat = provinces[0]))\n",
    "a6 = list(itertools.product([1, 0], repeat = provinces[1]))\n",
    "b = list(itertools.product([1, 0], repeat = dc))\n",
    "mp_loc_encoded = [[0, 0, 1, 1, 2, 2],\n",
    "                  [0, 1, 2, 3, 4, 5]]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "province_disruptions = [[x,y] for x in a6 for y in b]\n",
    "num_Scenarios = len(province_disruptions)\n",
    "plant_failure = [[None]*plants for x in range(2**provinces[1])]\n",
    "for k in range(len(plant_failure)):\n",
    "    for i in range(plants):\n",
    "        ind = mp_loc_encoded[1][i]\n",
    "        plant_failure[k][i] = a6[k][ind]\n",
    "Scen = [[x,y] for x in plant_failure for y in b]\n",
    "p_scen = []\n",
    "for s in range(len(province_disruptions)):\n",
    "    p_i = (p_running**(np.sum(province_disruptions[s][0]) + np.sum(province_disruptions[s][1])))*(p_failure**(provinces[1] + dc - (np.sum(province_disruptions[s][0]) + np.sum(province_disruptions[s][1]))))\n",
    "    p_scen.append(p_i)\n",
    "    \n",
    "#with open(path + '/Evaluation_Set.txt', 'w') as f:\n",
    " #   for item in Scen:\n",
    "  #      f.write(\"%s\\n\" % item)\n",
    "#f.close()\n",
    "#np.savetxt(\"p_scen.txt\", p_scen)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "N = [50, 100, 150, 200, 250, 300, 350]\n",
    "batches = 30\n",
    "Products = 3\n",
    "Market = 29\n",
    "dem = np.loadtxt(\"/home/dkabe/Model_brainstorming/SAA_Analysis/eval_set_demand.txt\").reshape(1024,3,29)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "source": [
    "random.seed(1)\n",
    "for num_scen in N:\n",
    "    for batch in range(batches):\n",
    "        indices = random.sample(range(len(Scen)), num_scen)\n",
    "        demand = np.array([dem[index] for index in indices])\n",
    "        sample_scenarios = [Scen[index] for index in indices]\n",
    "        p_sample_scenarios = [p_scen[index] for index in indices]\n",
    "        p_factor = 1/np.sum(p_sample_scenarios)\n",
    "        p_sample_scenarios = list(map(lambda x: x*p_factor, p_sample_scenarios))  \n",
    "        with open(path + 'Scenarios/' + str(num_scen) + '_' + str(batch) + '.txt', 'w') as f:\n",
    "            for item in sample_scenarios:\n",
    "                f.write(\"%s\\n\" % item)\n",
    "        f.close()\n",
    "        np.savetxt(path + 'Scen_probabilities/' + 'p_scen_' + str(num_scen) + '_' + str(batch) + '.txt', p_sample_scenarios)\n",
    "        np.savetxt(path + 'Scen_demand/' + 'demand_' + str(num_scen) + '_' + str(batch) + '.txt', demand.reshape((num_scen*Products, Market)))\n",
    "\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "source": [
    "counter = 0 \n",
    "for num_scen in N:\n",
    "    for batch in range(batches):\n",
    "        probs = np.loadtxt(path + 'Scen_probabilities/' + 'p_scen_' + str(num_scen) + '_' + str(batch) + '.txt')\n",
    "        counter += np.sum(probs)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "source": [
    "counter"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "180.0"
      ]
     },
     "metadata": {},
     "execution_count": 61
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "p1_mean = 137000\n",
    "p2_mean = 135000\n",
    "p3_mean = 133000\n",
    "\n",
    "p1_sd = 2650\n",
    "p2_sd = 8125\n",
    "p3_sd = 4000\n",
    "\n",
    "distribution_mat = [[p1_mean, p1_sd],\n",
    "                  [p2_mean, p2_sd],\n",
    "                  [p3_mean, p3_sd]]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "# forming evaluation set demand \n",
    "demand = np.zeros((1024, Products, Market))\n",
    "for s in range(len(Scen)):\n",
    "    demand[s][0] = np.round(np.random.normal(distribution_mat[0][0], distribution_mat[0][1], size = 29))\n",
    "    demand[s][1] = np.round(np.random.normal(distribution_mat[1][0], distribution_mat[1][1], size = 29))\n",
    "    demand[s][2] = np.round(np.random.normal(distribution_mat[2][0], distribution_mat[2][1], size = 29))\n",
    "\n",
    "#np.savetxt(\"eval_set_demand.txt\", demand.reshape((1024*3,29)))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "source": [
    "# eval set v2\n",
    "random.seed(2)\n",
    "for num_scen in N:\n",
    "    indices = random.sample(range(len(Scen)), 200)\n",
    "    scenarios = 25*[Scen[index] for index in indices]\n",
    "    p_sample_scenarios = 25*[p_scen[index] for index in indices]\n",
    "    p_factor = 1/np.sum(p_sample_scenarios)\n",
    "    p_sample_scenarios = list(map(lambda x: x*p_factor, p_sample_scenarios))\n",
    "    with open(path + 'Eval_Sets/' + str(num_scen) + '_scenarios' + '/evaluation_scenarios.txt', 'w') as f:\n",
    "      for item in scenarios:\n",
    "        f.write(\"%s\\n\" % item)\n",
    "    f.close()\n",
    "\n",
    "    np.savetxt(path + '/Eval_Sets/' + str(num_scen) + '_scenarios' + \"/p_scen.txt\", p_sample_scenarios)\n",
    "    \n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "source": [
    "random.seed(2)\n",
    "for num_scen in N:\n",
    "    demand = np.zeros((5000, Products, Market))\n",
    "    for s in range((5000)):\n",
    "        demand[s][0] = np.round(np.random.normal(distribution_mat[0][0], distribution_mat[0][1], size = 29))\n",
    "        demand[s][1] = np.round(np.random.normal(distribution_mat[1][0], distribution_mat[1][1], size = 29))\n",
    "        demand[s][2] = np.round(np.random.normal(distribution_mat[2][0], distribution_mat[2][1], size = 29))\n",
    "    np.savetxt(path + 'Eval_Sets/' + str(num_scen) + '_scenarios' + '/demand.txt', demand.reshape(5000*3,29))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "source": [
    "p_sample_scenarios[350]"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "1.4240291640478235e-07"
      ]
     },
     "metadata": {},
     "execution_count": 28
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "source": [
    "len(25*scenarios)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "5000"
      ]
     },
     "metadata": {},
     "execution_count": 20
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "source": [
    "path"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'/home/dkabe/Model_brainstorming/SAA_Analysis/'"
      ]
     },
     "metadata": {},
     "execution_count": 16
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "# 50 scenario confidence interval\n",
    "batches = 30"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "# version 1\n",
    "p_scen = np.loadtxt(\"/home/dkabe/Model_brainstorming/SAA_Analysis/p_scen.txt\")\n",
    "path = '/home/dkabe/Model_brainstorming/SAA_Analysis/'\n",
    "scenarios = [50, 100, 150, 200, 250, 300, 350]\n",
    "\n",
    "for scen in scenarios:\n",
    "    gaps = []\n",
    "    ub_averages = []\n",
    "    ub_max = []\n",
    "    objvals_lb = np.loadtxt(path + \"Objectives/\" + str(scen) + '_results.txt')\n",
    "    avg_lb = (np.mean(objvals_lb))\n",
    "    std_lb = (stdev(objvals_lb))\n",
    "    lbwidth = std_lb/math.sqrt(batches)*2.045\n",
    "    lbmin = round(avg_lb - lbwidth,2)\n",
    "    print(avg_lb, lbmin)\n",
    "    print('ci on lower bound = [', round(avg_lb-lbwidth,2), ',', round(avg_lb+lbwidth,2), ']')\n",
    "    for batch in range(batches):\n",
    "        objvals_ub = np.loadtxt(path + \"Upper_Bounds/\" + str(scen) + \"_scenarios/\" + str(scen) + \"_\" + str(batch) + \"_UB_results.txt\")\n",
    "        avg_ub = (np.sum(p_scen*objvals_ub))\n",
    "        std_ub = math.sqrt(np.sum(p_scen*((objvals_ub - avg_ub)**2)))\n",
    "        ubwidth = std_ub/math.sqrt(1024)*1.96\n",
    "        ubmax = round(avg_ub + ubwidth, 2)\n",
    "        gap = round(100*((ubmax - lbmin)/lbmin),2)\n",
    "        ub_averages.append(avg_ub)\n",
    "        gaps.append(gap)\n",
    "        ub_max.append(ubmax)\n",
    "    min_gap = min(gaps)\n",
    "    index = gaps.index(min_gap)\n",
    "    print(ub_averages[index], ub_max[index], min_gap)\n",
    "    "
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "19311784.417 18226921.71\n",
      "ci on lower bound = [ 18226921.71 , 20396647.12 ]\n",
      "18914133.458780024 19293062.4 5.85\n",
      "19727755.459666666 18856014.86\n",
      "ci on lower bound = [ 18856014.86 , 20599496.06 ]\n",
      "18914133.458780024 19293062.4 2.32\n",
      "19125208.860666666 18151827.33\n",
      "ci on lower bound = [ 18151827.33 , 20098590.39 ]\n",
      "18914133.458780024 19293062.4 6.29\n",
      "19203196.929 18574683.13\n",
      "ci on lower bound = [ 18574683.13 , 19831710.73 ]\n",
      "18914133.458780024 19293062.4 3.87\n",
      "18669362.847333334 17970296.67\n",
      "ci on lower bound = [ 17970296.67 , 19368429.02 ]\n",
      "18914133.458780024 19293062.4 7.36\n",
      "19322171.72633333 18960955.35\n",
      "ci on lower bound = [ 18960955.35 , 19683388.1 ]\n",
      "18914133.458780024 19293062.4 1.75\n",
      "18922742.623666666 18411084.25\n",
      "ci on lower bound = [ 18411084.25 , 19434401.0 ]\n",
      "18914133.458780024 19293062.4 4.79\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "# version 2\n",
    "path = '/home/dkabe/Model_brainstorming/SAA_Analysis/'\n",
    "scenarios = [50, 100, 150, 200, 250, 300, 350]\n",
    "\n",
    "for scen in scenarios:\n",
    "    p_scen = np.loadtxt('/home/dkabe/Model_brainstorming/SAA_Analysis/Eval_Sets/' + str(scen) + '_scenarios/p_scen.txt') \n",
    "    gaps = []\n",
    "    ub_averages = []\n",
    "    ub_max = []\n",
    "    objvals_lb = np.loadtxt(path + \"Objectives/\" + str(scen) + '_results.txt')\n",
    "    avg_lb = (np.mean(objvals_lb))\n",
    "    std_lb = (stdev(objvals_lb))\n",
    "    lbwidth = std_lb/math.sqrt(batches)*2.045\n",
    "    lbmin = round(avg_lb - lbwidth,2)\n",
    "    #print(avg_lb, lbmin)\n",
    "    #print('ci on lower bound = [', round(avg_lb-lbwidth,2), ',', round(avg_lb+lbwidth,2), ']')\n",
    "    for batch in range(batches):\n",
    "        objvals_ub = np.loadtxt(path + \"Upper_Bounds_v2/\" + str(scen) + \"_scenarios/\" + str(scen) + \"_\" + str(batch) + \"_UB_results.txt\")\n",
    "        avg_ub = (np.sum(p_scen*objvals_ub))\n",
    "        std_ub = math.sqrt(np.sum(p_scen*((objvals_ub - avg_ub)**2)))\n",
    "        ubwidth = std_ub/math.sqrt(5000)*1.96\n",
    "        ubmax = round(avg_ub + ubwidth, 2)\n",
    "        gap = round(100*((ubmax - lbmin)/lbmin),2)\n",
    "        ub_averages.append(avg_ub)\n",
    "        gaps.append(gap)\n",
    "        ub_max.append(ubmax)\n",
    "    min_gap = min(gaps)\n",
    "    index = gaps.index(min_gap)\n",
    "    #print(ub_averages[index], ub_max[index], min_gap)\n",
    "    print(avg_lb, \"\\t\", ub_averages[index], \"\\t\", lbmin, ub_max[index])"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "19311784.417 \t 18605628.685058296 \t 18226921.71 18712482.16\n",
      "19727755.459666666 \t 18951706.189399462 \t 18856014.86 19084614.59\n",
      "19125208.860666666 \t 20626974.88149371 \t 18151827.33 20871871.77\n",
      "19203196.929 \t 19082301.67707853 \t 18574683.13 19239697.55\n",
      "18669362.847333334 \t 18002294.71588643 \t 17970296.67 18276390.33\n",
      "19322171.72633333 \t 20659700.3648881 \t 18960955.35 20854499.91\n",
      "18922742.623666666 \t 19421882.753571518 \t 18411084.25 19623250.99\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# version 2 "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.7.4",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.4 64-bit ('env_gurobi': virtualenv)"
  },
  "interpreter": {
   "hash": "ab66d84091635e28aaa655d19dc257d938f7e6a1e4d5fb0a631906b26faaf625"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}