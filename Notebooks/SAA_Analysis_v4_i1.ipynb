{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "\n",
    "import numpy as np\n",
    "import itertools\n",
    "import random\n",
    "from statistics import stdev\n",
    "import math\n",
    "import ast"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "\n",
    "p_running = 0.9\n",
    "p_failure = 1 - p_running\n",
    "path = '/home/dkabe/Model_brainstorming/SAA_Analysis_v4/Instance_1/'"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "source": [
    "N = [64, 128, 192, 256, 320, 384]\n",
    "batches = 30\n",
    "Products = 3\n",
    "Market = 29\n",
    "demand_realization = 100\n",
    "text_file = open(path + 'Disruption_scenarios.txt', \"r\")\n",
    "ls = text_file.read().split('\\n')[:-1]\n",
    "Scenarios = list(map(lambda x: ast.literal_eval(x), ls))\n",
    "Probabilities = np.loadtxt(path + \"disruption_probabilities.txt\")\n",
    "num_disruption = len(Scenarios)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "p1_mean = 103500\n",
    "p2_mean = 101500\n",
    "p3_mean = 99750\n",
    "\n",
    "p1_sd = 1650\n",
    "p2_sd = 4125\n",
    "p3_sd = 2000\n",
    "\n",
    "distribution_mat = [[p1_mean, p1_sd],\n",
    "                  [p2_mean, p2_sd],\n",
    "                  [p3_mean, p3_sd]]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "source": [
    "\n",
    "np.random.seed(1)\n",
    "nominal_demand = np.zeros((Products, Market))\n",
    "for m in range(Products):\n",
    "    nominal_demand[m] = np.round(np.random.normal(distribution_mat[0][0], distribution_mat[0][1], size = 29))\n",
    "    nominal_demand[m] = np.round(np.random.normal(distribution_mat[1][0], distribution_mat[1][1], size = 29))\n",
    "    nominal_demand[m] = np.round(np.random.normal(distribution_mat[2][0], distribution_mat[2][1], size = 29))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "delta = np.arange(0.75, 1.255, 0.005)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "delta"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([0.75 , 0.755, 0.76 , 0.765, 0.77 , 0.775, 0.78 , 0.785, 0.79 ,\n",
       "       0.795, 0.8  , 0.805, 0.81 , 0.815, 0.82 , 0.825, 0.83 , 0.835,\n",
       "       0.84 , 0.845, 0.85 , 0.855, 0.86 , 0.865, 0.87 , 0.875, 0.88 ,\n",
       "       0.885, 0.89 , 0.895, 0.9  , 0.905, 0.91 , 0.915, 0.92 , 0.925,\n",
       "       0.93 , 0.935, 0.94 , 0.945, 0.95 , 0.955, 0.96 , 0.965, 0.97 ,\n",
       "       0.975, 0.98 , 0.985, 0.99 , 0.995, 1.   , 1.005, 1.01 , 1.015,\n",
       "       1.02 , 1.025, 1.03 , 1.035, 1.04 , 1.045, 1.05 , 1.055, 1.06 ,\n",
       "       1.065, 1.07 , 1.075, 1.08 , 1.085, 1.09 , 1.095, 1.1  , 1.105,\n",
       "       1.11 , 1.115, 1.12 , 1.125, 1.13 , 1.135, 1.14 , 1.145, 1.15 ,\n",
       "       1.155, 1.16 , 1.165, 1.17 , 1.175, 1.18 , 1.185, 1.19 , 1.195,\n",
       "       1.2  , 1.205, 1.21 , 1.215, 1.22 , 1.225, 1.23 , 1.235, 1.24 ,\n",
       "       1.245, 1.25 ])"
      ]
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "source": [
    "random.seed(1)\n",
    "demand = np.zeros((demand_realization, Products, Market))\n",
    "for r in range(demand_realization):\n",
    "    for m in range(Products):\n",
    "        for k in range(Market):\n",
    "            multiplier = random.choice(delta)\n",
    "            demand[r][m][k] = multiplier*nominal_demand[m][k]\n",
    "            "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "source": [
    "\n",
    "S = demand_realization*Scenarios\n",
    "S_demand = []\n",
    "S_prob = list(Probabilities)*demand_realization\n",
    "multiplier = sum(S_prob)\n",
    "S_prob = list(map(lambda x: x/multiplier, S_prob))\n",
    "for r in range(demand_realization):\n",
    "    S_demand+=([demand[r]]*num_disruption)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "source": [
    "len(S_demand)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "12800"
      ]
     },
     "metadata": {},
     "execution_count": 27
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "source": [
    "random.seed(2)\n",
    "evaluation_indices = random.sample(range(len(S)), 5000)\n",
    "evaluation_set = [S[index] for index in evaluation_indices]\n",
    "evaluation_demand = np.array([S_demand[index] for index in evaluation_indices])\n",
    "eval_probabilities = [S_prob[index] for index in evaluation_indices]\n",
    "p_factor = sum(eval_probabilities)\n",
    "eval_probabilities = list(map(lambda x: x/p_factor, eval_probabilities))\n",
    "with open(path + 'Evaluation_Set.txt', 'w') as f:\n",
    "    for item in evaluation_set:\n",
    "        f.write(\"%s\\n\" % item)\n",
    "f.close()\n",
    "np.savetxt(path + \"p_scen.txt\", eval_probabilities)\n",
    "np.savetxt(path + \"eval_set_demand.txt\", evaluation_demand.reshape((5000*3,29)))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "source": [
    "random.seed(1)\n",
    "for num_scen in N:\n",
    "    for batch in range(batches):\n",
    "        indices = random.sample(range(len(S)), num_scen)\n",
    "        sample_scenarios = [S[index] for index in indices]\n",
    "        p_sample_scenarios = [S_prob[index] for index in indices]\n",
    "        demand = np.array([S_demand[index] for index in indices])\n",
    "        p_factor = 1/np.sum(p_sample_scenarios)\n",
    "        p_sample_scenarios = list(map(lambda x: x*p_factor, p_sample_scenarios))  \n",
    "        with open(path + 'Scenarios/' + str(num_scen) + '_' + str(batch) + '.txt', 'w') as f:\n",
    "            for item in sample_scenarios:\n",
    "                f.write(\"%s\\n\" % item)\n",
    "        f.close()\n",
    "        np.savetxt(path + 'Scen_probabilities/' + 'p_scen_' + str(num_scen) + '_' + str(batch) + '.txt', p_sample_scenarios)\n",
    "        np.savetxt(path + 'Scen_demand/' + 'demand_' + str(num_scen) + '_' + str(batch) + '.txt', demand.reshape((num_scen*Products, Market)))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "# version 2\n",
    "batches = 30\n",
    "path = '/home/dkabe/Model_brainstorming/SAA_Analysis_v4/Instance_1/'\n",
    "N = [64, 128, 192, 256, 320, 384]\n",
    "p_scen = np.loadtxt('/home/dkabe/Model_brainstorming/SAA_Analysis_v4/Instance_1/p_scen.txt')[:1000]\n",
    "p_factor = 1/np.sum(p_scen)\n",
    "p_scen = list(map(lambda x: x*p_factor, p_scen))  \n",
    "\n",
    "p_factor = 1/np.sum(p_scen)\n",
    "p_scen = list(map(lambda x: x*p_factor, p_scen))  \n",
    "for scen in N:\n",
    "    gaps = []\n",
    "    ub_averages = []\n",
    "    ub_max = []\n",
    "    objvals_lb = np.loadtxt(path + \"Objectives/\" + str(scen) + '_results.txt')\n",
    "    avg_lb = (np.mean(objvals_lb))\n",
    "    std_lb = (stdev(objvals_lb))\n",
    "    lbwidth = std_lb/math.sqrt(batches)*2.045\n",
    "    lbmin = round(avg_lb - lbwidth,2)\n",
    "    #print(avg_lb, lbmin)\n",
    "    #print('ci on lower bound = [', round(avg_lb-lbwidth,2), ',', round(avg_lb+lbwidth,2), ']')\n",
    "    for batch in range(batches):\n",
    "        objvals_ub = np.loadtxt(path + \"Upper_Bounds/\" + str(scen) + \"_scenarios/\" + str(scen) + \"_\" + str(batch) + \"_UB_results.txt\")[:1000]\n",
    "        #objvals_ub = np.array([objvals_ub[index] for index in indices])\n",
    "        avg_ub = (np.sum(p_scen*objvals_ub))\n",
    "        std_ub = math.sqrt(np.sum(p_scen*((objvals_ub - avg_ub)**2)))\n",
    "        ubwidth = std_ub/math.sqrt(1000)*1.96\n",
    "        ubmax = round(avg_ub + ubwidth, 2)\n",
    "        gap = round(100*((ubmax - lbmin)/lbmin),2)\n",
    "        ub_averages.append(avg_ub)\n",
    "        gaps.append(gap)\n",
    "        ub_max.append(ubmax)\n",
    "    min_gap = min(filter(lambda x: x >= 0, gaps))\n",
    "    #min_gap = min(gaps)\n",
    "    index = gaps.index(min_gap)\n",
    "    #print(ub_averages[index], ub_max[index], min_gap)\n",
    "    print(avg_lb, \"\\t\", ub_averages[index], \"\\t\", lbmin, \"\\t\", ub_max[index], \"\\t\", min_gap)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "source": [
    "gaps"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[6.13,\n",
       " 10.8,\n",
       " 5.49,\n",
       " 4.07,\n",
       " 10.77,\n",
       " 6.96,\n",
       " 5.59,\n",
       " 8.01,\n",
       " 12.53,\n",
       " 10.66,\n",
       " 5.31,\n",
       " 8.99,\n",
       " 5.31,\n",
       " 3.57,\n",
       " 3.44,\n",
       " 6.96,\n",
       " 5.88,\n",
       " 9.15,\n",
       " 9.15,\n",
       " 12.37,\n",
       " 6.13,\n",
       " 6.26,\n",
       " 7.08,\n",
       " 3.57,\n",
       " 10.05,\n",
       " 10.66,\n",
       " 12.15,\n",
       " 3.62,\n",
       " 3.56,\n",
       " 4.22]"
      ]
     },
     "metadata": {},
     "execution_count": 21
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.7.4",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.4 64-bit ('env_gurobi': virtualenv)"
  },
  "interpreter": {
   "hash": "ab66d84091635e28aaa655d19dc257d938f7e6a1e4d5fb0a631906b26faaf625"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}